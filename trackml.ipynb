{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7878,"databundleVersionId":46689,"sourceType":"competition"}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-03T08:55:35.822380Z","iopub.execute_input":"2026-01-03T08:55:35.822705Z","iopub.status.idle":"2026-01-03T08:55:38.801534Z","shell.execute_reply.started":"2026-01-03T08:55:35.822672Z","shell.execute_reply":"2026-01-03T08:55:38.800447Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/trackml-particle-identification/train_sample.zip\n/kaggle/input/trackml-particle-identification/train_3.zip\n/kaggle/input/trackml-particle-identification/train_2.zip\n/kaggle/input/trackml-particle-identification/sample_submission.csv.zip\n/kaggle/input/trackml-particle-identification/train_5.zip\n/kaggle/input/trackml-particle-identification/detectors.zip\n/kaggle/input/trackml-particle-identification/test.zip\n/kaggle/input/trackml-particle-identification/blacklist_training.zip\n/kaggle/input/trackml-particle-identification/train_4.zip\n/kaggle/input/trackml-particle-identification/train_1.zip\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install torch_geometric torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:32:26.002271Z","iopub.execute_input":"2026-01-03T12:32:26.003012Z","iopub.status.idle":"2026-01-03T12:32:29.227641Z","shell.execute_reply.started":"2026-01-03T12:32:26.002956Z","shell.execute_reply":"2026-01-03T12:32:29.226968Z"}},"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\nRequirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\nRequirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt28cu126)\nRequirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt28cu126)\nRequirement already satisfied: torch-cluster in /usr/local/lib/python3.12/dist-packages (1.6.3+pt28cu126)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.10.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.15.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.11.12)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data, Dataset\nfrom torch_geometric.transforms import KNNGraph\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import TransformerConv\nimport numpy as np\nimport os\nimport pandas as pd\nimport pytorch_lightning as pl\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport zipfile\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom collections import Counter\nimport gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:33:07.377729Z","iopub.execute_input":"2026-01-03T12:33:07.378413Z","iopub.status.idle":"2026-01-03T12:33:07.383056Z","shell.execute_reply.started":"2026-01-03T12:33:07.378378Z","shell.execute_reply":"2026-01-03T12:33:07.382274Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()\nprint(\"âœ… GPU memory cleared\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:33:11.454640Z","iopub.execute_input":"2026-01-03T12:33:11.455202Z","iopub.status.idle":"2026-01-03T12:33:11.673897Z","shell.execute_reply.started":"2026-01-03T12:33:11.455165Z","shell.execute_reply":"2026-01-03T12:33:11.673265Z"}},"outputs":[{"name":"stdout","text":"âœ… GPU memory cleared\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\n# Check available GPU memory\nif torch.cuda.is_available():\n    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n    print(f\"ğŸ“Š Total GPU memory: {total_memory:.2f} GB\")\n    print(f\"ğŸ“Š Available GPU memory: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB allocated\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:33:19.261494Z","iopub.execute_input":"2026-01-03T12:33:19.262249Z","iopub.status.idle":"2026-01-03T12:33:19.266661Z","shell.execute_reply.started":"2026-01-03T12:33:19.262210Z","shell.execute_reply":"2026-01-03T12:33:19.266069Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š Total GPU memory: 14.74 GB\nğŸ“Š Available GPU memory: 0.00 GB allocated\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Data exploration utility\ndef explore_data_files(root):\n    \"\"\"Explore the structure of data files\"\"\"\n    print(\"=\"*60)\n    print(\"DATA FILE EXPLORATION\")\n    print(\"=\"*60)\n    \n    data_files = {\n        'train_sample': 'train_sample.zip',\n        'train_1': 'train_1.zip',\n        'train_2': 'train_2.zip',\n        'train_3': 'train_3.zip',\n        'train_4': 'train_4.zip',\n        'train_5': 'train_5.zip',\n        'test': 'test.zip',\n    }\n    \n    for name, filename in data_files.items():\n        filepath = os.path.join(root, filename)\n        if os.path.exists(filepath):\n            with zipfile.ZipFile(filepath, 'r') as z:\n                files = z.namelist()\n                events = len([f for f in files if f.endswith('-hits.csv')])\n                print(f\"\\n{name:15} ({filename:20}): {events:4} events\")\n        else:\n            print(f\"\\n{name:15} ({filename:20}): NOT FOUND\")\n    \n    print(\"\\n\" + \"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:35:53.815081Z","iopub.execute_input":"2026-01-03T12:35:53.815670Z","iopub.status.idle":"2026-01-03T12:35:53.821792Z","shell.execute_reply.started":"2026-01-03T12:35:53.815637Z","shell.execute_reply":"2026-01-03T12:35:53.821064Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Explore data before training\nroot = '/kaggle/input/trackml-particle-identification'\nexplore_data_files(root)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âš¡ QUICK TEST MODE ACTIVATED âš¡\")\nprint(\"=\"*60)\nprint(\"This configuration uses minimal data for rapid testing:\")\nprint(\"  â€¢ Training: 5 events (~2-3 min)\")\nprint(\"  â€¢ Validation: 3 events\")\nprint(\"  â€¢ Testing: 3 events\")\nprint(\"  â€¢ Epochs: 5\")\nprint(\"\\nPerfect for:\")\nprint(\"  âœ“ Verifying code runs without errors\")\nprint(\"  âœ“ Quick model architecture testing\")\nprint(\"  âœ“ Debugging and iteration\")\nprint(\"\\nğŸ’¡ For full training, modify these values:\")\nprint(\"  â€¢ train_dataset: n_events=50+ from train_1.zip\")\nprint(\"  â€¢ val_dataset: n_events=20+ from train_sample.zip\")\nprint(\"  â€¢ test_dataset: n_events=None (all 125 events)\")\nprint(\"  â€¢ trainer: max_epochs=20-30\")\nprint(\"=\"*60 + \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:35:57.509764Z","iopub.execute_input":"2026-01-03T12:35:57.510488Z","iopub.status.idle":"2026-01-03T12:35:57.822566Z","shell.execute_reply.started":"2026-01-03T12:35:57.510454Z","shell.execute_reply":"2026-01-03T12:35:57.821928Z"}},"outputs":[{"name":"stdout","text":"============================================================\nDATA FILE EXPLORATION\n============================================================\n\ntrain_sample    (train_sample.zip    ):  100 events\n\ntrain_1         (train_1.zip         ): 1770 events\n\ntrain_2         (train_2.zip         ): 1770 events\n\ntrain_3         (train_3.zip         ): 1770 events\n\ntrain_4         (train_4.zip         ): 1770 events\n\ntrain_5         (train_5.zip         ): 1770 events\n\ntest            (test.zip            ):  125 events\n\n============================================================\n\n============================================================\nâš¡ QUICK TEST MODE ACTIVATED âš¡\n============================================================\nThis configuration uses minimal data for rapid testing:\n  â€¢ Training: 5 events (~2-3 min)\n  â€¢ Validation: 3 events\n  â€¢ Testing: 3 events\n  â€¢ Epochs: 5\n\nPerfect for:\n  âœ“ Verifying code runs without errors\n  âœ“ Quick model architecture testing\n  âœ“ Debugging and iteration\n\nğŸ’¡ For full training, modify these values:\n  â€¢ train_dataset: n_events=50+ from train_1.zip\n  â€¢ val_dataset: n_events=20+ from train_sample.zip\n  â€¢ test_dataset: n_events=None (all 125 events)\n  â€¢ trainer: max_epochs=20-30\n============================================================\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Manual data loading from zip\ndef load_event(zip_path, inner_path):\n    with zipfile.ZipFile(zip_path, 'r') as z:\n        hits = pd.read_csv(z.open(f'{inner_path}-hits.csv'))\n        cells = pd.read_csv(z.open(f'{inner_path}-cells.csv'))\n        particles = pd.read_csv(z.open(f'{inner_path}-particles.csv'))\n        truth = pd.read_csv(z.open(f'{inner_path}-truth.csv'))\n    return hits, cells, particles, truth\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:36:01.869886Z","iopub.execute_input":"2026-01-03T12:36:01.870553Z","iopub.status.idle":"2026-01-03T12:36:01.874892Z","shell.execute_reply.started":"2026-01-03T12:36:01.870519Z","shell.execute_reply":"2026-01-03T12:36:01.874209Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Dataset class adjusted for Kaggle zip structure with memory-efficient sampling\nclass TrackMLDataset(Dataset):\n    def __init__(self, root, zip_name='train_sample.zip', n_events=8, transform=None, max_hits=30000):\n        super().__init__(root, transform=transform)\n        self.zip_path = os.path.join(root, zip_name)\n        self.max_hits = max_hits  # Configurable hit limit\n        # Reduce k from 8 to 6 to save memory\n        self.transform = transform or KNNGraph(k=6)\n        \n        # Dynamically extract unique event paths from zip namelist\n        self.inner_paths = []\n        with zipfile.ZipFile(self.zip_path, 'r') as z:\n            for fname in z.namelist():\n                if fname.endswith('-hits.csv'):\n                    inner = fname.rsplit('-hits.csv', 1)[0]\n                    self.inner_paths.append(inner)\n        self.inner_paths = sorted(set(self.inner_paths))[:n_events]\n\n    def len(self):\n        return len(self.inner_paths)\n\n    def get(self, idx):\n        inner_path = self.inner_paths[idx]\n        hits, cells, particles, truth = load_event(self.zip_path, inner_path)\n        \n        # MEMORY OPTIMIZATION: Sample hits if too many\n        if len(hits) > self.max_hits:\n            sample_idx = np.random.choice(len(hits), self.max_hits, replace=False)\n            sample_idx = np.sort(sample_idx)  # Keep order for consistency\n            hits = hits.iloc[sample_idx].reset_index(drop=True)\n            # Update truth to match sampled hits\n            truth = truth[truth['hit_id'].isin(hits['hit_id'])].reset_index(drop=True)\n        \n        # Node features (r, phi, z)\n        r = np.sqrt(hits['x']**2 + hits['y']**2).values\n        phi = np.arctan2(hits['y'], hits['x']).values\n        z = hits['z'].values\n        x = torch.tensor(np.stack([r, phi, z], axis=1), dtype=torch.float)\n        \n        # Store global coordinates for KNN calculation\n        pos = torch.tensor(hits[['x', 'y', 'z']].values, dtype=torch.float)\n        \n        data = Data(x=x, pos=pos)\n        \n        # Apply KNN Transform to create edges\n        if self.transform:\n            data = self.transform(data)\n            \n            # Label the edges: 1 if both hits belong to the same particle, else 0\n            hit_to_particle = truth.set_index('hit_id')['particle_id'].to_dict()\n            \n            raw_hit_ids = hits['hit_id'].values\n            edge_src_pids = np.array([hit_to_particle.get(raw_hit_ids[i], 0) for i in data.edge_index[0]])\n            edge_tgt_pids = np.array([hit_to_particle.get(raw_hit_ids[i], 0) for i in data.edge_index[1]])\n            \n            # Logic: same particle AND not noise (PID 0 is noise)\n            y = (edge_src_pids == edge_tgt_pids) & (edge_src_pids != 0)\n            data.y = torch.tensor(y, dtype=torch.float)\n            \n        return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:36:05.565973Z","iopub.execute_input":"2026-01-03T12:36:05.566625Z","iopub.status.idle":"2026-01-03T12:36:05.576811Z","shell.execute_reply.started":"2026-01-03T12:36:05.566589Z","shell.execute_reply":"2026-01-03T12:36:05.576059Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Model - Smaller architecture for memory efficiency\nclass TrackTransformer(torch.nn.Module):\n    def __init__(self, in_channels=3, hidden_channels=32, out_channels=1, heads=2):  # Reduced from 64/4 to 32/2\n        super().__init__()\n        self.hidden_channels = hidden_channels\n        self.heads = heads\n        \n        self.embed = torch.nn.Linear(in_channels, hidden_channels)\n        \n        # Edge dimension matches the OUTPUT of each layer\n        self.conv1 = TransformerConv(hidden_channels, hidden_channels, heads=heads, \n                                     dropout=0.1, edge_dim=hidden_channels, beta=True)\n        # After conv1: output is hidden_channels * heads = 64\n        self.conv2 = TransformerConv(hidden_channels * heads, hidden_channels, heads=heads, \n                                     dropout=0.1, edge_dim=hidden_channels * heads, beta=True)\n        # After conv2: output is hidden_channels * heads = 64\n        self.conv3 = TransformerConv(hidden_channels * heads, hidden_channels // heads, heads=heads, \n                                     dropout=0.1, edge_dim=hidden_channels * heads, beta=True)\n        \n        # Final edge classifier\n        self.lin_edge = torch.nn.Linear((hidden_channels // heads) * heads * 2, out_channels)\n\n    def forward(self, x, edge_index, batch=None):\n        x = F.relu(self.embed(x))\n        \n        # Layer 1: edge_attr size = 32\n        src, tgt = x[edge_index[0]], x[edge_index[1]]\n        edge_attr = torch.abs(src - tgt)\n        x = F.relu(self.conv1(x, edge_index, edge_attr))\n        \n        # Layer 2: edge_attr size = 64 (32 * 2 heads)\n        src, tgt = x[edge_index[0]], x[edge_index[1]]\n        edge_attr = torch.abs(src - tgt)\n        x = F.relu(self.conv2(x, edge_index, edge_attr))\n        \n        # Layer 3: edge_attr size = 64 (32 * 2 heads)\n        src, tgt = x[edge_index[0]], x[edge_index[1]]\n        edge_attr = torch.abs(src - tgt)\n        x = self.conv3(x, edge_index, edge_attr)\n        \n        # Concatenate source and target node embeddings for edge classification\n        edge_emb = torch.cat([x[edge_index[0]], x[edge_index[1]]], dim=-1)\n        return self.lin_edge(edge_emb).squeeze(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:36:08.824846Z","iopub.execute_input":"2026-01-03T12:36:08.825697Z","iopub.status.idle":"2026-01-03T12:36:08.834601Z","shell.execute_reply.started":"2026-01-03T12:36:08.825655Z","shell.execute_reply":"2026-01-03T12:36:08.833752Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class TrackLightning(pl.LightningModule):\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n        \n        # Storage for validation predictions\n        self.validation_step_outputs = []\n\n    def forward(self, batch):\n        return self.model(batch.x, batch.edge_index, batch.batch)\n\n    def training_step(self, batch, batch_idx):\n        logits = self(batch)\n        # Ensure target is float for BCEWithLogitsLoss\n        loss = self.loss_fn(logits, batch.y.float())\n        \n        with torch.no_grad():\n            preds = torch.sigmoid(logits) > 0.5\n            acc = (preds == batch.y).float().mean()\n        \n        self.log('train_loss', loss, prog_bar=True, batch_size=batch.num_graphs)\n        self.log('train_acc', acc, prog_bar=True, batch_size=batch.num_graphs)\n        \n        return loss\n    \n    def on_train_batch_end(self, outputs, batch, batch_idx):\n        # Memory management: manually clear cache if needed\n        if batch_idx % 5 == 0: \n            torch.cuda.empty_cache()\n\n    def validation_step(self, batch, batch_idx):\n        logits = self(batch)\n        loss = self.loss_fn(logits, batch.y.float())\n        \n        preds = (torch.sigmoid(logits) > 0.5).cpu()\n        targets = batch.y.cpu()\n        \n        # Store as a dictionary to keep things organized\n        output = {'preds': preds, 'targets': targets}\n        self.validation_step_outputs.append(output)\n        \n        acc = (preds == targets).float().mean()\n        self.log('val_loss', loss, prog_bar=True, batch_size=batch.num_graphs)\n        self.log('val_acc', acc, prog_bar=True, batch_size=batch.num_graphs)\n        \n        return loss\n    \n    def on_validation_epoch_end(self):\n        # Concatenate all stored predictions and targets\n        all_preds = torch.cat([x['preds'] for x in self.validation_step_outputs]).numpy()\n        all_targets = torch.cat([x['targets'] for x in self.validation_step_outputs]).numpy()\n        \n        # Calculate metrics\n        accuracy = accuracy_score(all_targets, all_preds)\n        precision = precision_score(all_targets, all_preds, zero_division=0)\n        recall = recall_score(all_targets, all_preds, zero_division=0)\n        f1 = f1_score(all_targets, all_preds, zero_division=0)\n        \n        # Log metrics - these will show up in your progress bar and logs \n        # instead of causing a print recursion crash\n        self.log('val_accuracy', accuracy, prog_bar=True)\n        self.log('val_precision', precision)\n        self.log('val_recall', recall)\n        self.log('val_f1', f1, prog_bar=True)\n        \n        # CRITICAL: Clear storage to free RAM and prevent RecursionError\n        self.validation_step_outputs.clear()\n        torch.cuda.empty_cache()\n\n    def configure_optimizers(self):\n        optimizer = AdamW(self.parameters(), lr=1e-3, weight_decay=1e-5)\n        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n        return {\n            'optimizer': optimizer, \n            'lr_scheduler': {\n                'scheduler': scheduler, \n                'monitor': 'val_loss'\n            }\n        }\n    def on_test_epoch_end(self):\n        return self.on_validation_epoch_end()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:51:59.118628Z","iopub.execute_input":"2026-01-03T12:51:59.119447Z","iopub.status.idle":"2026-01-03T12:51:59.130562Z","shell.execute_reply.started":"2026-01-03T12:51:59.119409Z","shell.execute_reply":"2026-01-03T12:51:59.129749Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Prepare data with train/val split using multiple training files\nroot = '/kaggle/input/trackml-particle-identification'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:42:48.625414Z","iopub.execute_input":"2026-01-03T12:42:48.626269Z","iopub.status.idle":"2026-01-03T12:42:48.629605Z","shell.execute_reply.started":"2026-01-03T12:42:48.626222Z","shell.execute_reply":"2026-01-03T12:42:48.628974Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Load training data with more events (can handle more with batching!)\nprint(\"\\nLoading training data...\")\ntrain_dataset = TrackMLDataset(root, zip_name='train_sample.zip', n_events=8)  # More events with batching!\nprint(f\"  Training events: {len(train_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:42:50.793137Z","iopub.execute_input":"2026-01-03T12:42:50.793871Z","iopub.status.idle":"2026-01-03T12:42:50.802398Z","shell.execute_reply.started":"2026-01-03T12:42:50.793832Z","shell.execute_reply":"2026-01-03T12:42:50.801763Z"}},"outputs":[{"name":"stdout","text":"\nLoading training data...\n  Training events: 8\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Load validation data\nprint(\"Loading validation data...\")\nval_dataset = TrackMLDataset(root, zip_name='train_sample.zip', n_events=4)\nprint(f\"  Validation events: {len(val_dataset)}\")\n\nfull_train_dataset = train_dataset\n\nprint(f\"\\n{'='*60}\")\nprint(f\"Dataset Summary:\")\nprint(f\"  Training:   {len(full_train_dataset)} events\")\nprint(f\"  Validation: {len(val_dataset)} events\")\nprint(f\"  Batch size: 2 events per batch (uses less memory)\")\nprint(f\"  Estimated training time: ~5-8 minutes\")\nprint(f\"{'='*60}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:42:52.987447Z","iopub.execute_input":"2026-01-03T12:42:52.987784Z","iopub.status.idle":"2026-01-03T12:42:52.996840Z","shell.execute_reply.started":"2026-01-03T12:42:52.987750Z","shell.execute_reply":"2026-01-03T12:42:52.996145Z"}},"outputs":[{"name":"stdout","text":"Loading validation data...\n  Validation events: 4\n\n============================================================\nDataset Summary:\n  Training:   8 events\n  Validation: 4 events\n  Batch size: 2 events per batch (uses less memory)\n  Estimated training time: ~5-8 minutes\n============================================================\n\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"BATCH_SIZE = 2  # Process 2 events at once\n\ntrain_loader = DataLoader(\n    full_train_dataset, \n    batch_size=BATCH_SIZE,  # Batch multiple graphs together!\n    shuffle=True, \n    num_workers=0,\n    pin_memory=True  # Faster GPU transfer\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=BATCH_SIZE,  # Same batch size for validation\n    shuffle=False, \n    num_workers=0,\n    pin_memory=True\n)\n\nprint(f\"âœ… DataLoaders created:\")\nprint(f\"   Training batches: {len(train_loader)} (batch_size={BATCH_SIZE})\")\nprint(f\"   Validation batches: {len(val_loader)} (batch_size={BATCH_SIZE})\")\nprint(f\"   Total training graphs: {len(full_train_dataset)}\")\nprint(f\"   Total validation graphs: {len(val_dataset)}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:42:55.850392Z","iopub.execute_input":"2026-01-03T12:42:55.851126Z","iopub.status.idle":"2026-01-03T12:42:55.856534Z","shell.execute_reply.started":"2026-01-03T12:42:55.851090Z","shell.execute_reply":"2026-01-03T12:42:55.855777Z"}},"outputs":[{"name":"stdout","text":"âœ… DataLoaders created:\n   Training batches: 4 (batch_size=2)\n   Validation batches: 2 (batch_size=2)\n   Total training graphs: 8\n   Total validation graphs: 4\n\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Train\nmodel = TrackTransformer()\nlightning_model = TrackLightning(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:42:59.322142Z","iopub.execute_input":"2026-01-03T12:42:59.322751Z","iopub.status.idle":"2026-01-03T12:42:59.332112Z","shell.execute_reply.started":"2026-01-03T12:42:59.322717Z","shell.execute_reply":"2026-01-03T12:42:59.331285Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n\n# 1. Setup Callbacks\ncheckpoint_callback = ModelCheckpoint(\n    monitor='val_f1',\n    dirpath='checkpoints',\n    filename='trackml-{epoch:02d}-{val_f1:.4f}',\n    save_top_k=3,\n    mode='max'\n)\n\nearly_stop_callback = EarlyStopping(\n    monitor='val_f1', # Changed to monitor F1 as it's better for TrackML\n    patience=5,\n    mode='max'\n)\n\n# 2. Initialize Trainer with Memory Optimizations\ntrainer = pl.Trainer(\n    max_epochs=5,\n    accelerator='gpu',\n    devices=1,\n    precision='16-mixed',       # Reduces VRAM usage by ~50%\n    accumulate_grad_batches=2,  # Simulates larger batch size\n    gradient_clip_val=1.0,      # Improves training stability\n    callbacks=[checkpoint_callback, early_stop_callback],\n    num_sanity_val_steps=1,     # Quick check before full training\n    log_every_n_steps=10        # Reduces console/logger clutter\n)\n\n# 3. Start Training\nprint(\"ğŸš€ Initializing training on GPU...\")\ntrainer.fit(lightning_model, train_loader, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:43:01.244073Z","iopub.execute_input":"2026-01-03T12:43:01.244368Z","iopub.status.idle":"2026-01-03T12:44:29.287762Z","shell.execute_reply.started":"2026-01-03T12:43:01.244338Z","shell.execute_reply":"2026-01-03T12:44:29.287061Z"}},"outputs":[{"name":"stderr","text":"Using 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n","output_type":"stream"},{"name":"stdout","text":"ğŸš€ Initializing training on GPU...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ model   â”‚ TrackTransformer  â”‚ 42.3 K â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ loss_fn â”‚ BCEWithLogitsLoss â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ model   â”‚ TrackTransformer  â”‚ 42.3 K â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ loss_fn â”‚ BCEWithLogitsLoss â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mTrainable params\u001b[0m: 42.3 K                                                                                           \n\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n\u001b[1mTotal params\u001b[0m: 42.3 K                                                                                               \n\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n\u001b[1mModules in train mode\u001b[0m: 28                                                                                          \n\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 42.3 K                                                                                           \n<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total params</span>: 42.3 K                                                                                               \n<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n<span style=\"font-weight: bold\">Modules in train mode</span>: 28                                                                                          \n<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a50df76b072e461fb677f4c0403cf38f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The \n'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n`num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The \n'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n`num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The \n'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n`num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The \n'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n`num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches (4)\nis smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you \nwant to see logs for the training epoch.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches (4)\nis smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you \nwant to see logs for the training epoch.\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"==================================================\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==================================================\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"`Trainer.fit` stopped: `max_epochs=5` reached.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# 1. Initialize and Load (Same as before)\nbase_model = TrackTransformer(in_channels=3, hidden_channels=32, out_channels=1, heads=2)\nmodel_eval = TrackLightning.load_from_checkpoint(\n    'checkpoints/trackml-epoch=02-val_f1=0.0528.ckpt', \n    model=base_model\n)\n\n# 2. Use validate() instead of test() to avoid the error\ntrainer.validate(model_eval, dataloaders=val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:52:27.517314Z","iopub.execute_input":"2026-01-03T12:52:27.517835Z","iopub.status.idle":"2026-01-03T12:52:32.474360Z","shell.execute_reply.started":"2026-01-03T12:52:27.517801Z","shell.execute_reply":"2026-01-03T12:52:32.473805Z"}},"outputs":[{"name":"stderr","text":"LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b830d86aa61a485c9d277b16fe886257"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.5498277544975281    \u001b[0m\u001b[35m \u001b[0mâ”‚\nâ”‚\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.5498277544975281    \u001b[0m\u001b[35m \u001b[0mâ”‚\nâ”‚\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.05163121223449707   \u001b[0m\u001b[35m \u001b[0mâ”‚\nâ”‚\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0mâ”‚\nâ”‚\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m  0.026981733739376068   \u001b[0m\u001b[35m \u001b[0mâ”‚\nâ”‚\u001b[36m \u001b[0m\u001b[36m       val_recall        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.5973190665245056    \u001b[0m\u001b[35m \u001b[0mâ”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\">      Validate metric      </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.5498277544975281     </span>â”‚\nâ”‚<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.5498277544975281     </span>â”‚\nâ”‚<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.05163121223449707    </span>â”‚\nâ”‚<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>â”‚\nâ”‚<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">   0.026981733739376068    </span>â”‚\nâ”‚<span style=\"color: #008080; text-decoration-color: #008080\">        val_recall         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.5973190665245056     </span>â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[{'val_loss': nan,\n  'val_acc': 0.5498277544975281,\n  'val_accuracy': 0.5498277544975281,\n  'val_precision': 0.026981733739376068,\n  'val_recall': 0.5973190665245056,\n  'val_f1': 0.05163121223449707}]"},"metadata":{}}],"execution_count":36}]}